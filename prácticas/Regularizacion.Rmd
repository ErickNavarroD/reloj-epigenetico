---
title: "Práctica 3: Introducción a glmnet"
author: "Erick Navarro"
date: "2025-07-09"
output: html_document 
---

¡Hola! En esta práctica vamos a aprender a usar la librería `glmnet` para realizar modelos de regularización. Utilizaremos un modelo muy sencillo con utilizando el ejemplo que viene en la documentación de la función. 

El primer paso es cargar la libraría

```{r}
#install.packages("glmnet")
library(glmnet)
#install.packages("caret")
#library(caret)
```

Ahora haremos un modelo muy simple con la función `glmnet`. Este paquete ajusta modelos de regularización a los datos. Realizaremos un modelo con LASSO, otro con Ridge regression, y otro con Elastic Net.

Después de cargar los datos, generaremos una matriz de datos con predictores, y un vector que corresponda a la variable de respuesta que queremos predecir. 

```{r}
set.seed(1)
x = matrix(rnorm(n = 100 * 20), # Numero de observaciones 
           100, 20) # Muestrear una matriz de 20x100 a partir de una distribucion normal con media de 0 y SD de 1. 
head(x) #Observar la estructura de los datos
y = rnorm(100) #Muestrear un vector de 100 elementos a partir de una distribucion normal con media de 0 y SD de 1. 
head(y) #Observar la estructura de los datos
```

En este caso, no dividiremos los datos en sets de prueba/test, dado que son simulados y podemos crear más. Pero en caso de hacerlo, en este momento debes de dividir tus datos aleatoriamente y asegurarte de que las respuestas estén similarmente distribuidas. También es buena idea explorar las covariables. 

```{r, eval=FALSE}
#Ejemplo
train.index <- caret::createDataPartition(dataset$respuesta, p = .8, list=FALSE)

train <- dataset[ train.index,]
valid  <- dataset[-train.index,]
table(train$respuesta)
table(valid$respuesta)
```

## RIDGE 

Ahora, ajustaremos los modelos utilizando cross-validation para tunear los hiperparámetros. Empezaremos por la regresión Ridge. 

```{r}
ridge.cv <- cv.glmnet(x,y,alpha=0,family="gaussian",type.measure = "mse", nfolds = 5 )
#plot result
plot(ridge.cv)
```

La función cv.glmnet encuentra el valor de lambda (que regula la función de penalización) que genera el modelo más simple y reduce lo más posible el error del modelo. Es común usar el valor de lambda que se encuentra un error estandar alejado del valor mínimo/óptimo de lambda (lambda.1se). Esto se debe a que el valor genera un modelo un poco más simple, que predice teóricamente igual que el valor de lambda mínimo, y es preferible utilizar el modelo más parsimonioso. 

```{r}
#Ver el valor mínimo de lambda
ridge.cv$lambda.min

#Escoger el valor de lambda para el modelo
(lambda_RIDGE <- ridge.cv$lambda.1se)

#Ver los coeficientes
coef(ridge.cv,s=lambda_RIDGE)
```

Ahora hagamos predicciones con base en un conjunto de datos nuevos. 

```{r}
newx = matrix(rnorm(10 * 20), 10, 20)
predict(ridge.cv, newx , s = lambda_RIDGE, type = "response")  # make predictions
```

## LASSO Regression

Ahora vamos a ajustar un modelo de LASSO. La diferencia entre LASSO y Ridge es que LASSO puede reducir los coeficientes de algunas variables a cero, lo que significa que elimina esas variables del modelo. Esto es útil para la selección de variables.

```{r}
lasso.cv <- cv.glmnet(x,y,alpha=1,family="gaussian",type.measure = "mse", nfolds = 5)
#plot result
plot(lasso.cv) 

#best value of lambda
lambda_lasso <- lasso.cv$lambda.1se
lambda_lasso

#regression coefficients
coef(lasso.cv,s=lambda_lasso)

pred_lasso <- predict(lasso.cv, newx, type="response", s=lambda_lasso) 

#caret::confusionMatrix(pred_lasso,valid$diabetes)
```

# Elastic Net

Ahora vamos a ajustar un modelo de Elastic Net. Elastic Net es una combinación de LASSO y Ridge. 

```{r}

elastic.cv <- cv.glmnet(x,y,alpha=0.5,family="gaussian",type.measure = "mse", nfolds= 5 )
plot(elastic.cv)
coef(elastic.cv,s=elastic.cv$lambda.1se)

pred_en <- predict(elastic.cv, newx, type="response", s="lambda.1se") 

## Caret is good for creating a grid
# model.caretb <- caret::train(y ~ x1 + x2 + x3, data=train, method="glmnet", 
#                            family = "gaussian", trControl = fitControl, 
#                            tuneGrid = tuneGridb, metric = "ROC")

```
